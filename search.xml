<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[记一次go语言debug调优实战]]></title>
    <url>%2F2021%2F03%2F27%2Fgolang-debug-optimize%2F</url>
    <content type="text"><![CDATA[在用go开发百度APP自动推送系统hermes的时候遇到了一个很诡异的问题，该系统的部分流程如下：hermes订阅了一个推送物料的MQ，由于要做小流量实验，通过一个Dispatcher将物料分成了两条流，分别写到不同的filter channel，Filter模块消费该channel并进行一些参数判断过滤，再写入store channel，Store模块消费该channel并通过redis去重，如果不重复则写入MySQL，并在redis里标记该物料已经处理过了，但是进程在跑了几分钟之后MQ订阅中止了，开始以为是测试环境MQ连接有问题，调试之后才发现是channel阻塞了。在这里记录下调试过程，包括Linux下常用调试命令free、ps、top、strace、pstack等和go的调试工具pprof的使用。 Linux调试系统内存占用在确认不是MQ连接的问题之后，先是怀疑OOM了，用free看了下机器内存使用情况，从”-/+ buffers/cache”这一行可以看到能够挪用的内存还有9869M，不是OOM。查看日志也确认没有OOM信息： 程序内存占用ps和top看下，占用的内存也并不高： go pprof调试在程序中加上pprof调试代码之后，查看goroutine堆栈信息，发现有一个异常信息：1goroutine 17 [chan send, 29 minutes, locked to thread] 堆栈信息开始于MQ订阅，阻塞于Dispatcher写入filter channel的时候，而Filter模块只是进行参数的判断过滤，没有进行网络请求或者IO操作，应该处理的很快，那可能是下游的store channel阻塞了，因为Store模块会请求Redis和MySQL，有网络请求和IO操作，处理比较慢，而Store模块是串行处理store channel里的数据的。于是将Store改为并行处理store channel，读取channel里的数据之后用goroutine进行处理。改完重新编译运行，发现MQ消费不会中断了！ 附：Linux几个调试命令输出内容字段解释free示例 输出结果对应字段说明 Mem：内存的使用情况 -/+ buffers/cache：表示物理内存已用多少，可用多少 Swap：交换空间的使用情况 关于buffers和cached的区别 A buffer is something that has yet to be “written” to disk. A cache is something that has been “read” from the disk and stored for later use. 计算 Mem total = used + free -/+ buffers/cache used = Mem used - Mem buffers - Mem cached free = Mem free + Mem buffers + Mem cached ps aux示例 输出结果对应字段说明 USER：进程的所有者 PID：进程ID号 %CPU：CPU占用率 %MEM：内存占用率 VSZ：虚拟内存使用量(单位KB) RSS：占用的固定内存量(单位KB) TTY：所在终端 STAT：进程状态 START：被启动的时间 TIME：实际使用CPU的时间 COMMAND：命令名称与参数 进程状态说明：D Uninterruptible sleep (usually IO)R Running or runnable (on run queue)S Interruptible sleep (waiting for an event to complete)T Stopped, either by a job control signal or because it is being traced.W paging (not valid since the 2.6.xx kernel)X dead (should never be seen)Z Defunct (“zombie”) process, terminated but not reaped by its parent. For BSD formats and when the stat keyword is used, additional characters may be displayed:&lt; high-priority (not nice to other users)N low-priority (nice to other users)L has pages locked into memory (for real-time and custom IO)s is a session leaderl is multi-threaded (using CLONE_THREAD, like NPTL pthreads do)+ is in the foreground process group 参考【Linux学习】Linux free 命令学习]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>Go</tag>
        <tag>Pprof</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac下Python2升级到Python3之后yd包不兼容问题踩坑历程]]></title>
    <url>%2F2020%2F05%2F03%2Fpy2-py3-yd-trouble-for-mac%2F</url>
    <content type="text"><![CDATA[最近用Mac brew安装一些包的时候顺带把Python从2.7升级到了3.7，导致之前在Python2下安装的很多包用不了了，例如yd、ipython、musicbox等：123╭─zuolicong@zuolicongdeAir ~╰─$ musicboxzsh: /usr/local/bin/musicbox: bad interpreter: /usr/local/opt/python/bin/python2.7: no such file or directory 平时用yd命令翻译单词还是挺方便的，于是就想着索性用pip3再安装一遍，反正Python2后面也要被淘汰了。然而以为很简单的事，却一顿折腾。运行pip3 install yd先报了这么一个错：1ModuleNotFoundError: No module named &apos;version&apos; 踩坑历程既然没有version包，那就再安装一个呗，于是pip3 install version，然而又报这个：1importError: cannot import name &apos;izip_longest&apos; 在网上查了下，itertools.izip在pyhton3中已被去掉了，zip成为内置的方法。解决方法是找到version包源文件中使用了”from itertools import izip_longest”的文件， 将izip_longest改为zip_longest，再手动安装，然而/usr/local/lib/python3.7/site-packages目录下也没有pip3下载的version包源文件，我试着用pip3 download version，仍然报上面那个错。看来只能去官网下载了：https://pypi.org/project/version/ 官网的version包链接到了https://github.com/keleshev/version ，可以直接下载zip文件，然后执行以下命令就可以安装version了：12345678910╭─zuolicong@zuolicongdeAir ~/python-code╰─$ pip3 install ./version-master.zipProcessing ./version-master.zipBuilding wheels for collected packages: version Building wheel for version (setup.py) ... done Created wheel for version: filename=version-0.1.2-py3-none-any.whl size=3249 sha256=d7f32866382d5d711c6e72e0a877ac2062fc7f25bed901567cbabd9168b17abc Stored in directory: /Users/zuolicong/Library/Caches/pip/wheels/25/58/94/317ecc66e2db4df75bb89ea3bf33401b3de1360fdb984f0428Successfully built versionInstalling collected packages: versionSuccessfully installed version-0.1.2 可以发现官网上的version包其实对Python2和Python3做了兼容：1234if sys.version_info &gt;= (3, 0): from itertools import zip_longest as izip_longestelse: from itertools import izip_longest 再运行pip3 install yd命令，bingo，安装成功，然而我还是太年轻，使用yd的时候又遇到一系列兼容问题：1234567Traceback (most recent call last): File &quot;/usr/local/bin/yd&quot;, line 5, in &lt;module&gt; from yd.yd import main File &quot;/usr/local/lib/python3.7/site-packages/yd/yd.py&quot;, line 131 print output ^SyntaxError: Missing parentheses in call to &apos;print&apos;. Did you mean print(output)? Python2中的”print output”在Python3中需要改成”print(output)” 123456Traceback (most recent call last): File &quot;/usr/local/bin/yd&quot;, line 5, in &lt;module&gt; from yd.yd import main File &quot;/usr/local/lib/python3.7/site-packages/yd/yd.py&quot;, line 4, in &lt;module&gt; import environModuleNotFoundError: No module named &apos;environ&apos; 继续pip3 install environ 123456789Traceback (most recent call last): File &quot;/usr/local/bin/yd&quot;, line 5, in &lt;module&gt; from yd.yd import main File &quot;/usr/local/lib/python3.7/site-packages/yd/yd.py&quot;, line 4, in &lt;module&gt; import environ File &quot;/usr/local/lib/python3.7/site-packages/environ.py&quot;, line 114 raise ValueError, &quot;No frame marked with %s.&quot; % fname ^SyntaxError: invalid syntax Python3中raise用法需要改成：raise ValueError(“No frame marked with %s.” % fname) 12345678910Traceback (most recent call last): File &quot;/usr/local/bin/yd&quot;, line 5, in &lt;module&gt; from yd.yd import main File &quot;/usr/local/lib/python3.7/site-packages/yd/yd.py&quot;, line 4, in &lt;module&gt; import environ File &quot;/usr/local/lib/python3.7/site-packages/environ.py&quot;, line 250, in &lt;module&gt; ctx = Environ(None) File &quot;/usr/local/lib/python3.7/site-packages/environ.py&quot;, line 105, in __init__ elif isinstance(frame, basestring):NameError: name &apos;basestring&apos; is not defined Python3中”basestring”需要改成”str” 然而无解的来了：123456Traceback (most recent call last): File &quot;/usr/local/bin/yd&quot;, line 5, in &lt;module&gt; from yd.yd import main File &quot;/usr/local/lib/python3.7/site-packages/yd/yd.py&quot;, line 7, in &lt;module&gt; import ydsearchModuleNotFoundError: No module named &apos;ydsearch&apos; 执行pip3 install ydsearch报：12ERROR: Could not find a version that satisfies the requirement ydsearch (from versions: none)ERROR: No matching distribution found for ydsearch 这么说来Python3压根就不支持yd包，害我还折腾了这么长时间。于是想到go是不是有类似的包可以替代，于是github上搜了下发现了这个：https://github.com/TimothyYe/ydict ，于是1go get -v github.com/TimothyYe/ydict 嗯，真香。 一点想法只能说Python 2和3兼容性真的太差，如果项目想从2升级到3成本太高，导致生态有点割裂。感觉设计者初期没太想好。不过我等屁民也不好评判大佬当初的想法，只能尽量避免踩坑，或者寻求可替代的方案，比如go。当然不同的语言使用的场景不同，适合的才是最好的。]]></content>
      <tags>
        <tag>Go</tag>
        <tag>Python</tag>
        <tag>pip</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[以旧换新项目中的微服务实践]]></title>
    <url>%2F2018%2F05%2F01%2Fmicroservice-in-old-for-new%2F</url>
    <content type="text"><![CDATA[微服务在近几年比较火，公司也在使用微服务架构。我在最近参与开发的以旧换新项目中也进行了一些微服务相关的实践，在这里总结一下遇到的问题和收获。 项目简介该项目主要是针对印度商城，用户用旧手机换取优惠券，抵扣购买新手机的部分费用。流程如下图所示，用户在web端输入手机IMEI信息，后端调用cashify的接口获取报价及报价id，或者用app进行检测（使用cashify提供的SDK）获取报价和报价id，再调用以旧换新服务生成以旧换新券。用户下单的时候可以使用券，调用支付组成服务以及订单组的接口完成交易，物流组负责发货相关功能，实际配送由第三方物流公司Ekart完成。Ekart将新手机派送给用户，并回收用户的旧手机，回收时会进行质检，没问题了会把旧手机派送给cashify，cashify把旧手机的钱打给我们。 我主要负责和cashify对接接口、商城后端生成以旧换新券流程中的相关接口以及以旧换新券服务。以旧换新券服务使用公司的SOA框架，其它项目通过thrift调用以旧换新券服务。 使用微服务的原因以旧换新券被做成了一个单独的服务，主要有一下几点好处： 首先，比较安全。作为独立的服务，可以限制只有内网的ip才能访问，不对外暴露；此外，由于使用thrift协议，需要使用SDK才能请求相应的接口，很大程度上避免了恶意攻击； 其次，以旧换新券服务的代码和数据库都部署在独立的机器上，即使该服务挂了，也不会影响商城其它的功能。当遇到流量比较大的情况时，可以单独给服务加机器，提高机器的使用率； 再者，可以降低业务的耦合度，避免单体应用代码过于庞大臃肿的情况。 遇到的问题和解决方法服务与商城后端解耦不够充分最开始我考虑的是，以旧换新券后续可能还有别的生成途径，不一定要通过请求cashify的接口获取报价来生成，于是我就把请求cashify的逻辑都放到商城后端来做，请求完之后再调以旧换新券服务生成券，后来发现这样做存在很大的问题：在PC或m站，用户输入手机的IMEI号来生成以旧换新券，商城后端得先调用服务判断该IMEI号是否已经生成了券，生成的券是否已经过期，如果没有生成过券或者生成的券已经过期了就会调用cashify的接口获取报价和报价ID等信息，并根据这些信息再次调用服务生成券，而服务中生成券逻辑需要再次查询数据库判断是否满足生成券的条件，相当于商城和服务中有重复的代码。于是将调用cashify接口的逻辑迁移到服务中进行，使服务和商城后端不再耦合。 其实最开始的思路是有问题的，即使以旧换新券还有别的生成途径，这些和生成券相关的逻辑都应该放到一起，充分和商城代码解耦。 并发情况下数据不一致的问题上面提到过，在PC或m站生成券的时候会先根据IMEI号判读是否满足生成券的条件，如果满足就会调用cashify的接口获取报价和报价ID并生成券，记录在数据库中。但是当两个相同的IMEI号同时请求时就会有问题，这两个请求同时去查数据库发现该IMEI号满足生成券的条件，就都去请求cashify的接口，这时cashify会生成两个报价ID，最终数据库保存的是先生成的那个报价ID，而最新生成的报价ID才是有效的，这就导致在优惠券使用之后订单组根据报价ID回调cashify的时候不成功。 最终解决方法是在redis里设置一个过期时间为30秒的key，标记某个IMEI在30秒之内是否已经请求过这个接口，如果请求过，直接返回请求过于频繁的信息，保证同一个IMEI不会同时请求cashify的接口生成两个报价ID；再就是根据日志修复之前有问题的数据；另外，之所以正常情况下（不是刷接口）也会出现两个相同的IMEI号同时请求，是因为用户在点击生成按钮之后发现没有反应，或者是手抖，连续点了两下，所以前端也需要进行相应的优化，在用户点击一次之后，显示一个类似loading的效果，不让用户继续点。 抢购流量大对以旧换新券服务造成压力付款页面会调以旧换新券服务获取当前用户可用的券，抢购的时候流量比较大，服务接口的错误率比较高，直接导致有些用户付不了款。解决的方法如下： 每次用户生成以旧换新券的时候都在redis里加个key标记该用户有以旧换新券，该key的过期时间和券的过期时间一致。在付款页面先通过redis里的标记判断该用户是否有以旧换新券，有才会去请求服务，没有直接不请求，这样就将没有以旧换新券的流量都挡在了外面，极大的减轻了服务的压力。需要说明的一点是，用户使用券的时候也不去改这个标记，因为用户可能有多张券，维护这个标记的成本很高，就算用户只有不可用的券，大不了这部分用户的流量都打到服务上，压力也不会很大。 在付款页面将调用以旧换新券列表的接口降级，即使接口有问题也不报错，不影响付款流程的进行。 接口幂等退款的时候为了保证整个退款流程走通，券的退回接口可能会被调用多次，因此退回接口设置了幂等，即使某张券已经退回成功，如果再次请求退回该张券，还是返回成功（不需要修改数据库）。支付组成服务在调以旧换新券服务的退回接口时，可能由于网络原因没有接收到正确的返回结果（实际上已经退回成功），这时会重试三次，如果还是失败，就交给消息队列处理，由于接口设置了幂等，最终调用方会收到退回成功的返回结果。 错误号和Log ID商城和服务中的错误号最好是统一的，二者之间不要有冲突，这样排查问题的时候更方便。对于同一个请求，商城和服务中用同一个Log ID来记录日志，便于追踪问题（这点项目之前的逻辑已经是这样做的）。]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>Go</tag>
        <tag>微服务</tag>
        <tag>RPC</tag>
        <tag>Thrift</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac docker内请求http(s)失败的问题处理]]></title>
    <url>%2F2017%2F12%2F23%2Fdocker-for-mac-localhost-issue%2F</url>
    <content type="text"><![CDATA[新建了一个docker容器，发现在容器内运行go get命令时会报错： 1234567[root@27a3532133fa bin]# go get -u -v github.com/nsf/gocodegithub.com/nsf/gocode (download)# cd /home/work/data/www/go/src/github.com/nsf/gocode; git pull --ff-onlyerror: Failed connect to github.com:8888; Operation now in progress while accessing https://github.com/nsf/gocode/info/refsfatal: HTTP request failedpackage github.com/nsf/gocode: exit status 1 访问github.com时莫名其妙的多了一个8888端口，查了相关资料发现是Mac新版的docker加了个http_proxy代理：12[root@27a3532133fa bin]# echo $http_proxydocker.for.mac.localhost:8888 找了很长时间也没发现怎么去掉这个http_proxy，最后发现可以将http_proxy这个环境变量定义为空，就可以把原来那个值覆盖掉，于是在~/.bash_profile加上1export http_proxy=&quot;&quot; 再source ~/.bash_profile就可以了。]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
        <tag>Mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IM系统redis迁移到codis实践]]></title>
    <url>%2F2017%2F04%2F26%2Fim-redis-to-codis%2F</url>
    <content type="text"><![CDATA[公司决定使用自己搭建的codis集群代替阿里云的redis，二者性能差别不大，但是自运维的codis成本更低，同时也借这次迁移来规范key的命名，统一命名成”系统(必须):子系统(必须):存储类型(可选，cache|storage):数据(必须):版本(可选):其它(可选)”的形式，方便维护。我负责IM即时通信系统的redis迁移。IM使用redis的地方很多，并且数据量很大，例如消息拉链、联系人、最近一条消息、未读消息数、黑名单、频率及敏感词限制、Token等，而消息拉链、最近一条消息和未读消息数是进行持久存储的，因此这些数据需要进行迁移。 方案为了不影响用户的使用，代码上线定在凌晨一点。数据迁移到codis的同时还要修改key，因此不能直接使用redis-port等工具将旧的redis里面的数据同步到新的codis集群，最终决定写脚本进行数据迁移。先使用keys命令模糊匹配出旧redis里的所有key，取出数据然后设置新的key批量保存到codis集群中。消息拉链的数据量很大，可以先进行一次全量的数据迁移，代码上线之前再进行一次增量数据迁移。最近一条消息和未读消息数数据时效性比较大，也在代码上线前进行同步。具体步骤如下： 将代码中记录redis key的常量文件备份一份，将原来的key修改成规范形式，并添加codis的配置文件及连接方法，写脚本通过备份的redis key文件从旧数据库读数据，然后批量写入codis集群； 在beta机器上跑脚本全量迁移消息拉链数据； 上线前IM系统停止服务，避免在上线过程中有数据写入； 从MySQL数据库取出全量迁移消息拉链之后新增的数据，添加到codis，并迁移最近一条消息和未读消息数的数据； 通过查看日志、自测等方法验证数据迁移是否成功； 代码上线； QA进行回归测试 遇到的问题及解决方法 数据迁移脚本运行时间很长(全量迁移消息拉链的脚本运行了5个小时左右)，如果直接运行脚本，断网或者终端与服务器连接断开会导致脚本停止运行解决方法：使用nohup在后台运行脚本，如下所示，并且在退出服务器时要通过exit命令退出，不能直接关掉，否则进程也会中止。 1nohup php cli.php redis_migrate migrateTotal &amp;&gt;&gt; /apps2/tmp/im/redis_migrate_migrateTotal.log 2&gt;&amp;1 &amp; 日志文件太大（最大的一个有1.8G），beta机器的一个磁盘打满了，导致进程结束解决方法：通过df命令查看磁盘空间使用情况，选择剩余空间比较大的磁盘打日志，这里选择/dev/xvdc1，即/apps2文件夹下面。 一次mset太多键值对数据，报Segmentation fault，如图：解决方法：先对数据进行分组，如5000个键值对为一组，然后循环进行mset，代码见第三部分。 从MySQL数据库查消息拉链的增量数据，报timeout exception，如图：根据日志可以看出这是一个慢查询，sql语句如下，查看表结构发现update_time字段没有建索引，而且数据量很大（查了下一对一聊天记录表有36133336条数据），所以查询慢，而另外一个字段create_time建了联合索引，根据最左前缀法则，使用create_time代替update_time将用到索引，问题得到解决。 12345678-- 慢查询sqlSELECT * FROM im_message_info_single WHERE update_time &gt; "2017-04-25 23:07:51";-- create_time和sender_r字段建立的联合索引KEY `idx_createtime_send_r` (`create_time`,`sender_r`)-- 优化之后的sqlSELECT * FROM im_message_info_single WHERE create_time &gt; "2017-04-25 23:07:51"; 使用keys命令获取所有用户一对一聊天未读消息数的key时，redis报”read error on connection”错误，如图：google了一下发现是数据量太大，读取超时的原因，通过setOption命令设置不超时解决，参见：https://nil.sh/RedisException-with-message-read-error-on-connection.html 迁完之后发现codis里找不到数据，可能是db不对，默认是db 0，通过select命令选择数据所在db之后再查看。 相关代码所有业务的消息拉链都是采用sorted set结构，所有业务的最后一条消息都是采用string结构，社区、考研、金囿、群组这几个业务的未读消息数采用hash结构，系统未读消息采用sorted set结构，一对一聊天的未读消息数采用string结构，sorted set、string和hash这三种结构的数据分别先通过keys命令获取保存所有key的数组，然后调用以下函数（略去Action函数）将数据迁移到codis。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118class RedisMigrateTask extends \Phalcon\Cli\Task &#123; const CHUNK_SIZE = 5000; // 数据分组大小 public $redisInstance = null; // redis实例 public $codisInstance = null; // codis实例 /** * 批量迁移sorted set数据 * @param $oldKeys array 存储旧key的数组 * @param $oldPrefix string 旧key前缀 * @param $newPrefix string 新key前缀 */ public function migrateSortedSetData($oldKeys, $oldPrefix, $newPrefix) &#123; if ($oldKeys === false) &#123; echo __METHOD__ . ' [' . date('Y-m-d H:i:s') . "] get keys [&#123;$oldPrefix&#125;*] failed!" . PHP_EOL; &#125; elseif (empty($oldKeys)) &#123; echo __METHOD__ . ' [' . date('Y-m-d H:i:s') . "] keys [&#123;$oldPrefix&#125;*] are empty!" . PHP_EOL; &#125; else &#123; echo __METHOD__ . ' [' . date('Y-m-d H:i:s') . "] get keys [&#123;$oldPrefix&#125;*] successfully!" . PHP_EOL; foreach ($oldKeys as $oldKey) &#123; $newKey = $this-&gt;getNewKey($oldKey, $oldPrefix, $newPrefix); $sortedSetData = $this-&gt;redisInstance-&gt;zRange($oldKey, 0, -1, true); $items = []; $logArr = []; foreach ($sortedSetData as $val =&gt; $score) &#123; $items[] = $score; $items[] = $val; $logArr[] = $score . ':' . $val; &#125; array_unshift($items, $newKey); $num = call_user_func_array([$this-&gt;codisInstance, 'zAdd'], $items); // 添加成功个数 if ($num === false) &#123; echo __METHOD__ . ' [' . date('Y-m-d H:i:s') . "] old key [&#123;$oldKey&#125;] failed to migrate to codis! old score=&gt;value: " . join(',', $logArr) . PHP_EOL; &#125; elseif ($num == 0) &#123; echo __METHOD__ . ' [' . date('Y-m-d H:i:s') . "] old key [&#123;$oldKey&#125;] has existed and is the same! old score=&gt;value: " . join(',', $logArr) . PHP_EOL; &#125; else &#123; echo __METHOD__ . ' [' . date('Y-m-d H:i:s') . "] old key [&#123;$oldKey&#125;] with &#123;$num&#125; values was migrated to codis successfully! old score=&gt;value: " . join(',', $logArr) . PHP_EOL; &#125; &#125; &#125; &#125; /** * 分组批量迁移string数据。数据太多全量用mset会报Segmentation fault, 分组mget, mset * @param $oldKeys * @param $oldPrefix * @param $newPrefix */ public function migrateKvDataChunk($oldKeys, $oldPrefix, $newPrefix) &#123; if ($oldKeys === false) &#123; echo __METHOD__ . ' [' . date('Y-m-d H:i:s') . "] get keys [&#123;$oldPrefix&#125;*] failed!" . PHP_EOL; &#125; elseif (empty($oldKeys)) &#123; echo __METHOD__ . ' [' . date('Y-m-d H:i:s') . "] keys [&#123;$oldPrefix&#125;*] are empty!" . PHP_EOL; &#125; else &#123; echo __METHOD__ . ' [' . date('Y-m-d H:i:s') . "] get keys [&#123;$oldPrefix&#125;*] successfully!" . PHP_EOL; $oldKeysChunk = array_chunk($oldKeys, self::CHUNK_SIZE); foreach ($oldKeysChunk as $oldkeysGroup) &#123; $valuesGroup = $this-&gt;redisInstance-&gt;mget($oldkeysGroup); $valuesGroupAssoc = []; foreach ($oldkeysGroup as $idx =&gt; $oldKey) &#123; $newKey = $this-&gt;getNewKey($oldKey, $oldPrefix, $newPrefix); $valuesGroupAssoc[$newKey] = $valuesGroup[$idx]; &#125; $ret = $this-&gt;codisInstance-&gt;mset($valuesGroupAssoc); // bool值 if ($ret) &#123; echo __METHOD__ . ' [' . date('Y-m-d H:i:s') . "] old kvs was migrated to codis successfully! old keys: " . join(',', $oldkeysGroup) . PHP_EOL; &#125; else &#123; echo __METHOD__ . ' [' . date('Y-m-d H:i:s') . "] old kvs failed to migrate to codis! old keys: " . join(',', $oldkeysGroup) . PHP_EOL; &#125; &#125; &#125; &#125; /** * 批量迁移hash数据 * @param $oldKeys * @param $oldPrefix * @param $newPrefix */ public function migrateHashData($oldKeys, $oldPrefix, $newPrefix) &#123; if ($oldKeys === false) &#123; echo __METHOD__ . ' [' . date('Y-m-d H:i:s') . "] get keys [&#123;$oldPrefix&#125;*] failed!" . PHP_EOL; &#125; elseif (empty($oldKeys)) &#123; echo __METHOD__ . ' [' . date('Y-m-d H:i:s') . "] keys [&#123;$oldPrefix&#125;*] are empty!" . PHP_EOL; &#125; else &#123; echo __METHOD__ . ' [' . date('Y-m-d H:i:s') . "] get keys [&#123;$oldPrefix&#125;*] successfully!" . PHP_EOL; foreach ($oldKeys as $oldKey) &#123; $hashData = $this-&gt;redisInstance-&gt;hGetAll($oldKey); $newKey = $this-&gt;getNewKey($oldKey, $oldPrefix, $newPrefix); $ret = $this-&gt;codisInstance-&gt;hMset($newKey, $hashData); // bool值 $logArr = []; foreach ($hashData as $hashKey =&gt; $hashVal) &#123; $logArr[] = $hashKey . ':' . $hashVal; &#125; if ($ret) &#123; echo __METHOD__ . ' [' . date('Y-m-d H:i:s') . "] old hash key [&#123;$oldKey&#125;] was migrated to codis successfully! old hash data: " . join(',', $logArr) . PHP_EOL; &#125; else &#123; echo __METHOD__ . ' [' . date('Y-m-d H:i:s') . "] old hash key [&#123;$oldKey&#125;] failed to migrate to codis! old hash data: " . join(',', $logArr) . PHP_EOL; &#125; &#125; &#125; &#125; /** * 生成新的key * @param $oldKey string 旧redis的key * @param $oldPrefix string 旧key前缀 * @param $newPrefix string 新key前缀 * @return string */ public function getNewKey($oldKey, $oldPrefix, $newPrefix) &#123; $offset = strlen($oldPrefix); $suffix = substr($oldKey, $offset); $newKey = $newPrefix . $suffix; return $newKey; &#125;&#125;]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>Codis</tag>
        <tag>PHP</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git打tag的方法和技巧]]></title>
    <url>%2F2016%2F01%2F23%2Fgit-tag%2F</url>
    <content type="text"><![CDATA[使用git作为版本控制工具，在代码上线之前需要打tag，便于团队有条不紊地上线代码。在这里总结一下打tag的方法与可能用到的技巧。 打tag并上线的常规流程一般是基于master分支打tag并推送tag到远程仓库，然后上线。要上线的代码合到master分支上之后，切换到master分支，pull最新代码，然后查看远程仓库的最新tag（假设为release_im_v0.0.9.8），在其基础上打tag release_im_v0.0.9.9。然后查看线上tag是哪一个（假设为release_im_v0.0.9.7），将新打的tag与线上tag进行diff，看代码有没有冲突，或者有没有别人合到master上但是暂时还不能上线的代码，如果没有问题，就可以把tag推送到远程仓库，然后请QA君帮忙上线。需要注意的是不能直接在线上tag的基础上加一作为新的tag，因为在你打tag期间团队其他人可能也打了tag，只是还没来得及上线而已，为避免冲突，需要基于远程仓库的最新tag打新tag。打tag并上线的流程如下： 12345678$ git checkout master$ git pull$ git tag|grep im|tail #查看远程仓库含有im的最新tag$ git tag -a release_im_v0.0.9.9 -m &apos;im咨询记录更改&apos; #一般打含有附注的标签$ git diff release_im_v0.0.9.7 release_im_v0.0.9.9 #如果改动比较多，也可以在gitlab上进行diff（当然要先push）#如果diff没有问题，就可以把tag推送到远程仓库，远程仓库如果是origin，则可省略origin$ git push [origin] release_im_v0.0.9.9 #推送具体的tag到远程仓库$ git push [origin] --tags #一次推送所有的tag到远程仓库 如果diff有冲突，或者master分支上含有不能上线的代码，或者要修改一个线上的bug比较紧急，就需要基于线上tag拉分支，把自己的修改的代码应用到该分支，然后在该分支上打tag上线。需要注意的是，基于自己的分支打tag上完线，还是要把该分支合到master上，不然自己改动的代码会被后面基于master的tag所覆盖。 基于线上tag修改代码并上线当需要解决线上bug比较紧急，则需要基于线上tag拉分支，在该分支修改代码并打tag上线。步骤如下（依然假设线上tag为release_im_v0.0.9.7，远程仓库最新tag为release_im_v0.0.9.8）：1234567$ git fetch --tags #查看远程仓库的tag$ git branch new_branch release_im_v0.0.9.7 #基于线上tag拉分支new_branch$ git checkout new_branch #切到该分支并修改代码解决bug$ git commit -am &apos;fix bug&apos; #tag默认打在最新提交的commit上$ git tag -a release_im_v0.0.9.9 -m &apos;fix bug&apos; $ git diff release_im_v0.0.9.7 release_im_v0.0.9.9$ git push --tags git cherry-pick的用法当需要把某个分支的某次commit应用到另外一个分支，git cherry-pick命令就派上用场了。假设我们现在在a分支上，该分支上有一个commit（假设其哈希码为d986206）需要应用到b分支上，那么可以这么做：1234$ git log --oneline #查看a分支commit历史找到需要应用到b分支上的commit的哈希码为d986206$ git show d986206 #确认commit内容$ git checkout b$ git cherry-pick d986206 基于线上tag打补丁并上线假如我们在自己的test分支修改了很多代码，合到master之后发现master不能上线，而且该分支同时修改了两个相关的线上的tag（例如PC站和手机m站），需要分别把相应的修改应用到相应的tag上，并上线，由于commit的次数比较多，用cherry-pick就比较麻烦，这时我们就需要打补丁了。现在假设PC站线上tag和远程仓库最新tag都是release_www_v3.2.2.6，手机m站线上tag和远程仓库最新tag都是release_m_v3.0.8.3，运用第二部分中的方法基于线上tag分别拉取PC站和m站的分支www-patch和m-patch。首先我们在自己的分支（这里是test分支）运行 git log –oneline 查看commit信息：发现544cf8c（主站获取id）、86721b7（m站获取id）、3971048（获取主站name）和f788477（获取m站name）这四次commit是需要上线的改动，于是我们将当前test分支与fb20a04（建立m类）这次commit进行diff以查看前四个commit的内容，确认无误后就可以打补丁了： 1$ git diff fb20a04 test &gt; patch 用vim打开patch文件截取部分如下：接下来切换到需要应用补丁的分支并应用该补丁：123456$ git checkout www-patch$ git apply patch #在www-patch分支应用补丁$ git diff #查看应用补丁之后的diff以确认无误$ rm patch #删除patch文件，git不需要追踪该文件，便于commit$ git commit -am &apos;apply patch&apos;$ git tag -a release_www_v3.2.2.7 -m &apos;打补丁上线&apos; 当然也可以把patch文件放在~/目录下，假设代码文件夹也在~/目录下，然后这样打补丁： 12345$ git diff fb20a04 test &gt; ~/patch$ git checkout www-patch$ patch -p1&lt;~/patch$ git commit -am &apos;apply patch&apos;$ git tag -a release_www_v3.2.2.7 接下来就是打手机m站的tag，这时我们就可以用git cherry-pick方法了，先在www-patch分支查看应用补丁的commit：然后应用到m-patch分支： 12345$ git checkout m-patch$ git cherry-pick 584f3ef$ git commit -am &apos;apply patch&apos;$ git tag -a release_m_v3.0.8.4 -m &apos;打补丁上线&apos;$ git push --tags #最后把新打的tag都推送到远程仓库以上线 基于特定的commit打tag假如我们想基于cf57ec4（建立www类）这次commit打tag，可以这样做： 1$ git tag -a www0.9.9 cf57ec4 -m &apos;建立www类&apos; 运行git show www0.9.9命令查看该tag信息，可以看到是基于cf57ec4（建立www类）这次commit打的：打tag时如果不指定commit，则默认基于当前分支的最新一次commit打。]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F404.html</url>
    <content type="text"><![CDATA[]]></content>
  </entry>
  <entry>
    <title><![CDATA[about]]></title>
    <url>%2Fabout%2Findex.html</url>
    <content type="text"><![CDATA[brief 我觉得最好的人生状态，是追求踮踮脚才能够到的东西。像我们这么倔强的家伙，有想做的事，有喜欢的人，就算再够呛，也得试试啊！ contact zuolicong@foxmail.com]]></content>
  </entry>
  <entry>
    <title><![CDATA[All categories]]></title>
    <url>%2Fcategories%2Findex.html</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[All tags]]></title>
    <url>%2Ftags%2Findex.html</url>
    <content type="text"></content>
  </entry>
</search>
